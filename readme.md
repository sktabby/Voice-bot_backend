# ğŸ™ï¸ Multilingual AI Voice Bot  
### Sarvam Saarika v2.5 + Groq LLM

---

## ğŸ“Œ Project Overview

This project implements a **multilingual AI voice bot** that allows users to **speak in their preferred language** (Hindi, English, Marathi, etc.), processes the input using AI, and responds back **in the same language** as both **text and optional speech**.

The system is designed using a **modular, service-based architecture** so that each part of the pipeline can be reused, replaced, or extended independently.

---

## ğŸ¯ Core Idea

- Users speak naturally in any supported language  
- Speech is converted into text  
- **All AI reasoning is performed in English** for better LLM accuracy  
- The response is translated back into the **userâ€™s original language**  
- UI shows both:
  - English (intermediate output)
  - Final translated output (user-facing)

This approach balances **user comfort** and **AI quality**.

---

## ğŸ§  Why These Technologies?

### Why Sarvam Saarika v2.5?

We use **Sarvam Saarika v2.5** (`model="saarika:v2.5"`) as a **single unified model** for:

- Speech-to-Text (STT)
- Language Detection
- Translation (User Language â‡„ English)

**Benefits:**
- One model handles the entire speech & language pipeline
- Consistent multilingual behavior
- Reduced system complexity
- Strong support for Indian languages

---

### Why English as the Internal LLM Language?

LLMs perform best when:
- Prompts are written in English
- System instructions are consistent
- Reasoning chains are not fragmented across languages

**Design decision:**
- Convert all user input â†’ English before LLM
- Convert LLM output â†’ userâ€™s original language after processing

---

### Why Groq LLM?

Groq is used for:
- Low-latency inference
- Stable and predictable responses
- Applying a fixed **Advisor System Prompt**

This ensures structured, polite, and guidance-oriented answers.

---

## ğŸ” End-to-End System Flow

```text
User Audio
â†’ Sarvam Saarika (Speech-to-Text)
â†’ Sarvam Saarika (Language Detection)
â†’ Sarvam Saarika (Translate to English)
â†’ Groq LLM (Advisor Prompt)
â†’ Response Generated (English)
â†’ UI shows English output
â†’ Sarvam Saarika (Translate back to original language)
â†’ UI shows final translated output
â†’ (Optional) Text-to-Speech



ğŸ” Step-by-Step Processing
1ï¸âƒ£ User Audio Input

User speaks via the microphone in the web UI.

Why:
Voice interaction is faster and more natural, especially for non-English users.

2ï¸âƒ£ Speech-to-Text (STT)

Model: saarika:v2.5

Converts raw audio into text.

Why:
LLMs operate on text, not audio.

3ï¸âƒ£ Language Detection

Model: saarika:v2.5

Detects the language spoken by the user.

Why:

Determines if translation is required

Ensures the response returns in the same language

Maintains consistent user experience

4ï¸âƒ£ Translation to English

Model: saarika:v2.5

Translates user text into English (if required).

Why:
English provides better reasoning and prompt stability for LLMs.

5ï¸âƒ£ LLM Processing (Groq)

English input is sent to Groq with an Advisor System Prompt.

Why:
This is where intent understanding, reasoning, and response generation occur.

6ï¸âƒ£ UI Display (English Output)

English response is shown in the UI.

Why this is useful:

Debugging

Transparency for reviewers

Validation of translations

7ï¸âƒ£ Translation Back to User Language

Model: saarika:v2.5

LLM response is translated back to the userâ€™s original language.

8ï¸âƒ£ UI Display (Final Output)

The translated response is displayed as the primary user output.

9ï¸âƒ£ Text-to-Speech (Optional)

Final translated text can be converted to speech and played back.

Why:
Completes a full voice â†’ voice interaction loop.

ğŸ§± Project Folder Structure
VOICE_BOT/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ .env.example
â”‚   â”œâ”€â”€ uploads/
â”‚   â”œâ”€â”€ chatbot/
â”‚   â”‚   â”œâ”€â”€ education_advisor.py
â”‚   â”‚   â””â”€â”€ groq_advisor.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ clients.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ sessions.py
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ voicebot.py
â”‚   â”‚   â”œâ”€â”€ chat.py
â”‚   â”‚   â”œâ”€â”€ health.py
â”‚   â”‚   â””â”€â”€ reset.py
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â””â”€â”€ chat.py
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ stt_service.py
â”‚       â”œâ”€â”€ translate_service.py
â”‚       â”œâ”€â”€ llm_service.py
â”‚       â””â”€â”€ storage_service.py
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ index.html
    â”œâ”€â”€ app.js
    â”œâ”€â”€ api.js
    â”œâ”€â”€ recorder.js
    â”œâ”€â”€ dom.js
    â”œâ”€â”€ session.js
    â”œâ”€â”€ styles.css
    â””â”€â”€ vite.config.js

ğŸ§© Modular Architecture & Reusability
services/ â€” Business Logic Layer

Each service has a single responsibility:

stt_service.py â†’ Speech processing

translate_service.py â†’ Language translation

llm_service.py â†’ LLM interaction

storage_service.py â†’ Audio/file storage

Reusable across:

Web voice bots

Mobile assistants

IVR / call-center systems

Messaging bots

routes/ â€” API Layer

Handles HTTP endpoints and delegates logic to services.

Keeps routes clean and readable.

chatbot/ â€” AI Behavior Layer

Defines:

Advisor personality

Tone and response structure

New bots can be added without changing the pipeline.

core/ â€” Shared Infrastructure

Manages:

Configuration

External client initialization

Session handling